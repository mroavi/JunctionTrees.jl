<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Background · JunctionTrees.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="JunctionTrees.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">JunctionTrees.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Background</a><ul class="internal"><li><a class="tocitem" href="#The-inference-problem"><span>The inference problem</span></a></li><li><a class="tocitem" href="#The-junction-tree-algorithm"><span>The junction tree algorithm</span></a></li><li><a class="tocitem" href="#Compiler-based-framework"><span>Compiler-based framework</span></a></li></ul></li><li><a class="tocitem" href="../usage/">Usage</a></li><li><span class="tocitem">Vizualization</span><ul><li><a class="tocitem" href="../visualization/junction_trees/">Junction trees</a></li><li><a class="tocitem" href="../visualization/markov_random_fields/">Markov random fields</a></li></ul></li><li><span class="tocitem">File formats</span><ul><li><a class="tocitem" href="../file_formats/uai/">UAI</a></li><li><a class="tocitem" href="../file_formats/pace/">PACE</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../library/public/">Public</a></li><li><a class="tocitem" href="../library/internals/">Internals</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Background</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mroavi/JunctionTrees.jl/blob/master/docs/src/background.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h1><p>The junction tree algorithm is an efficient method to perform Bayesian inference in probabilistic graphical models, such as Bayesian Networks or Markov random fields. The general problem is to calculate the conditional probability of a variable or a set of variables, given observed values of another set of variables. This is known as the inference problem.</p><h2 id="The-inference-problem"><a class="docs-heading-anchor" href="#The-inference-problem">The inference problem</a><a id="The-inference-problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-inference-problem" title="Permalink"></a></h2><p>Given a set of <strong>random variables</strong> <span>$\bm{V}$</span> and their <strong>joint distribution</strong> <span>$P(\bm{V})$</span>, compute one or more conditional distributions over a set of <strong>query variables</strong> <span>$\bm{Q}$</span> given observations <span>$\bm{e}$</span> for the set of <strong>observed variables</strong> <span>$\bm{E}$</span>.</p><p><img src="../the-inference-problem.svg" alt/></p><h2 id="The-junction-tree-algorithm"><a class="docs-heading-anchor" href="#The-junction-tree-algorithm">The junction tree algorithm</a><a id="The-junction-tree-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-junction-tree-algorithm" title="Permalink"></a></h2><p>We briefly describe the junction tree algorithm (JTA). For a more elaborate presentation, see <sup class="footnote-reference"><a id="citeref-huang1996inference" href="#footnote-huang1996inference">[huang1996inference]</a></sup>. The figure below presents an overview of the JTA.</p><p><img src="../pptc-flow-diagram.svg" alt/></p><p>A probabilistic graphical model (PGM) is the input to the JTA. PGMs illustrate the mathematical modeling of reasoning in the presence of uncertainty. Bayesian networks and Markov random fields are popular types of PGMs. Consider the Bayesian network shown in the figure below known as the <em>ASIA network</em> <sup class="footnote-reference"><a id="citeref-lauritzen1988local" href="#footnote-lauritzen1988local">[lauritzen1988local]</a></sup>. It is a simplified example from the context of medical diagnosis that describes the probabilistic relationships between different random variables corresponding to possible diseases, symptoms, risk factors and test results. It consists of a graph <span>$G = (\bm{V},\mathcal{E})$</span> and a probability distribution <span>$P(\bm{V})$</span> where <span>$G$</span> is a directed acyclic graph, <span>$\bm{V}$</span> is the set of variables and <span>$\mathcal{E}$</span> is the set of edges connecting the variables. We assume all variables to be discrete. Each variable <span>$V$</span> is quantified with a <em>conditional probability distribution</em> <span>$P(V \mid pa(V))$</span> where <span>$pa(V)$</span> are the parents of <span>$V$</span>. These conditional probability distributions together with the graph <span>$G$</span> induce a <em>joint probability distribution</em> over <span>$P(\bm{V})$</span>, given by</p><p class="math-container">\[P(\bm{V}) = \prod_{V\in\bm{V}} P(V \mid pa(V)).\]</p><table><tr><th style="text-align: center"><strong>Random variable</strong></th><th style="text-align: left"><strong>Meaning</strong></th></tr><tr><td style="text-align: center"><span>$A$</span></td><td style="text-align: left">Recent trip to Asia</td></tr><tr><td style="text-align: center"><span>$T$</span></td><td style="text-align: left">Patient has tuberculosis</td></tr><tr><td style="text-align: center"><span>$S$</span></td><td style="text-align: left">Patient is a smoker</td></tr><tr><td style="text-align: center"><span>$L$</span></td><td style="text-align: left">Patient has lung cancer</td></tr><tr><td style="text-align: center"><span>$B$</span></td><td style="text-align: left">Patient has bronchitis</td></tr><tr><td style="text-align: center"><span>$E$</span></td><td style="text-align: left">Patient hast <span>$T$</span> and/or <span>$L$</span></td></tr><tr><td style="text-align: center"><span>$X$</span></td><td style="text-align: left">Chest X-Ray is positive</td></tr><tr><td style="text-align: center"><span>$D$</span></td><td style="text-align: left">Patient has dyspnoea</td></tr></table><p><img src="../asia-bayesian-network.svg" alt/></p><h3 id="Graphical-transformation"><a class="docs-heading-anchor" href="#Graphical-transformation">Graphical transformation</a><a id="Graphical-transformation-1"></a><a class="docs-heading-anchor-permalink" href="#Graphical-transformation" title="Permalink"></a></h3><p>JTA performs probabilistic inference on a secondary structure known as a <em>junction tree</em>. A junction tree is constructed from a PGM by means of three graphical transformations: <em>moralization</em>, <em>triangulation</em>, and <em>connection of clusters</em>.</p><h4 id="Moralization"><a class="docs-heading-anchor" href="#Moralization">Moralization</a><a id="Moralization-1"></a><a class="docs-heading-anchor-permalink" href="#Moralization" title="Permalink"></a></h4><p>Moralization converts a directed acyclic graph into a undirected graph by dropping the directions of the edges and connecting the parents of each node. The figure below shows the corresponding moral graph of the Bayesian network in the figure above. The arrows point to the edges introduced after the transformation.</p><p><img src="../asia-moral-graph.svg" alt/></p><h4 id="Triangulation"><a class="docs-heading-anchor" href="#Triangulation">Triangulation</a><a id="Triangulation-1"></a><a class="docs-heading-anchor-permalink" href="#Triangulation" title="Permalink"></a></h4><p>Triangulation of an undirected graph is carried out by connecting two non-adjacent nodes in every cycle of length greater than three. The figure below shows a triangulated graph of the moral graph in the figure above. The arrow points to the edge introduced after the transformation. Note that, in general, there is more than one way of triangulating a given undirected graph. An optimal triangulation is one that minimizes the sum of the state space sizes of the <em>maximal cliques</em><sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> (denoted with colored boundaries in the figure below). This problem is NP-complete <sup class="footnote-reference"><a id="citeref-arnborg1987complexity" href="#footnote-arnborg1987complexity">[arnborg1987complexity]</a></sup>.</p><p><img src="../asia-triangulated-graph.svg" alt/></p><h4 id="Connection-of-clusters"><a class="docs-heading-anchor" href="#Connection-of-clusters">Connection of clusters</a><a id="Connection-of-clusters-1"></a><a class="docs-heading-anchor-permalink" href="#Connection-of-clusters" title="Permalink"></a></h4><p>The maximal cliques of the triangulated graph correspond to the nodes of the junction tree. We call these <em>clusters</em>. Clusters are then connected in a tree structure such that the <em>running intersection property</em> is satisfied: given two clusters <span>$\bm{X}$</span> and <span>$\bm{Y}$</span> in the tree, all clusters on the path between <span>$\bm{X}$</span> and <span>$\bm{Y}$</span> contain <span>$\bm{X} \cap \bm{Y}$</span>. Each edge is labeled with the intersection of the adjacent clusters. Such labels are called separator sets or <em>sepsets</em>. <sup class="footnote-reference"><a id="citeref-jensen1994optimal" href="#footnote-jensen1994optimal">[jensen1994optimal]</a></sup> present an optimal method to construct a junction tree from a triangulated graph. The figure below shows the result of applying this method to the triangulated graph in the figure above. Clusters are depicted as large circles and sepsets as rectangles. The color of clusters correspond to the maximal cliques of the triangulated graph (figure above). The encircled variables indicate which conditional probability distributions in the equation presented in section <a href="#The-junction-tree-algorithm">The junction tree algorithm</a> were multiplied into which cluster potentials of the junction tree.</p><p><img src="../asia-junction-tree.svg" alt/></p><h3 id="Initialization"><a class="docs-heading-anchor" href="#Initialization">Initialization</a><a id="Initialization-1"></a><a class="docs-heading-anchor-permalink" href="#Initialization" title="Permalink"></a></h3><p>Each cluster <span>${\bf X}$</span> in the junction tree is associated with a <em>potential</em> <span>$\psi_{{\bf X}}$</span>. A potential is a function over a set of variables <span>$\bm{V}$</span> that maps each instantiation <span>$\bm{V} = \bm{v}$</span> into a nonnegative number. First, all cluster potentials in the junction tree are initialized to unity. Then, each conditional probability distribution <span>$P(V \mid pa(V))$</span> in the equation presented in section <a href="#The-junction-tree-algorithm">The junction tree algorithm</a> is multiplied into a cluster potential <span>${\bf X}$</span> that contains its variable and its parents:</p><p class="math-container">\[\psi_{{\bf X}} \leftarrow \psi_{{\bf X}} \cdot P(V \mid pa(V)).\]</p><p>Note that a probability distribution is a special case of a potential. The encircled variables in the figure above indicate which conditional distributions in the Bayesian network figure were multiplied into which cluster potentials of our running example.</p><h3 id="Observation-entry"><a class="docs-heading-anchor" href="#Observation-entry">Observation entry</a><a id="Observation-entry-1"></a><a class="docs-heading-anchor-permalink" href="#Observation-entry" title="Permalink"></a></h3><p>Observations take the form of <span>${\bf E=e}$</span>, where <span>${\bf e}$</span> is the instantiation of the set of variables <span>${\bf E}$</span>. These are incorporated into the junction tree by finding a cluster potential <span>$\psi_{{\bf X}}$</span> for each evidence variable in <span>${\bf E}$</span> that contains it and setting all its entries that are not consistent with the evidence to zero. This operation is known as a <em>reduction</em> in the PGM literature <sup class="footnote-reference"><a id="citeref-koller2009probabilistic" href="#footnote-koller2009probabilistic">[koller2009probabilistic]</a></sup>.</p><h3 id="Propagation"><a class="docs-heading-anchor" href="#Propagation">Propagation</a><a id="Propagation-1"></a><a class="docs-heading-anchor-permalink" href="#Propagation" title="Permalink"></a></h3><p>Propagation refers to a series of synchronized local manipulations between clusters that guarantee consistency throughout the entire junction tree. These manipulations are called <em>messages</em>. The propagation of messages begins by designating an arbitrary cluster as the <em>root</em>, which gives direction to the edges of the junction tree. Messages then flow between clusters in two recursive phases: an <em>inward</em> and an <em>outward</em> phase. In the inward phase, each cluster passes a message to its parent. In the outward phase, each cluster passes a message to each of its children. A cluster passes a message to a neighbor only after it has received messages from all its <em>other</em> neighbors. A message from cluster <span>${\bf X}$</span> to cluster <span>${\bf Y}$</span> is a potential <span>$\phi_{{\bf X} \rightarrow {\bf Y}}$</span> defined by</p><p class="math-container">\[\phi_{{\bf X} \rightarrow {\bf Y}} =
\sum_{{\bf X} \setminus {\bf Y}} \psi_{{\bf X}} \prod_{{\bf N} \in
\mathcal{N}_{{\bf X} \setminus {\bf Y}}} \phi_{{\bf N} \rightarrow {\bf X}},\]</p><p>where <span>$\psi_{{\bf X}}$</span> is the cluster potential of <span>${\bf X}$</span> and <span>$\mathcal{N}_{{\bf X}}$</span> is the set of neighbors of <span>${\bf X}$</span>. The figure below shows an admissible schedule for the propagation of messages of our running example.</p><p><img src="../asia-message-passing.svg" alt/></p><h3 id="Marginalization"><a class="docs-heading-anchor" href="#Marginalization">Marginalization</a><a id="Marginalization-1"></a><a class="docs-heading-anchor-permalink" href="#Marginalization" title="Permalink"></a></h3><p>After the propagation phase, each edge holds two messages; one in each direction. The joint marginal probabilities for each sepset are given by the product of the two messages passing through the corresponding edge, i.e.</p><p class="math-container">\[P(S_{{\bf X}{\bf Y}}, {\bf E=e}) = \phi_{{\bf X} \rightarrow {\bf Y}} \cdot
  \phi_{{\bf Y} \rightarrow {\bf X}},\]</p><p>where <span>${\bf X}$</span> and <span>${\bf Y}$</span> are adjacent clusters. On the other hand, the joint marginal probabilities for each cluster are given by the product of the cluster&#39;s incoming messages and its potential, i.e.</p><p class="math-container">\[P({\bf X}, {\bf E=e}) = \psi_{{\bf X}} \prod_{{\bf N} \in \mathcal{N}_{{\bf
X}}} \phi_{{\bf N} \rightarrow {\bf X}}.\]</p><p>The marginal probability <span>$P(V,{\bf E=e})$</span> for each variable of interest <span>$V$</span> is then computed from the joint marginal of a sepset or cluster containing <span>$V$</span>. This is achieved by marginalizing all other variables:</p><p class="math-container">\[P(V,{\bf E=e}) = \sum_{{\bf X^\prime} \setminus V} P({\bf X^\prime}, {\bf
E=e}),\]</p><p>where <span>${\bf X^\prime}$</span> is a sepset or cluster potential that contains <span>$V$</span>.</p><h3 id="Normalization"><a class="docs-heading-anchor" href="#Normalization">Normalization</a><a id="Normalization-1"></a><a class="docs-heading-anchor-permalink" href="#Normalization" title="Permalink"></a></h3><p>The last step is to compute <span>$P(V \mid {\bf E=e})$</span> for each variable of interest <span>$V$</span>. We do so by normalizing <span>$P(V, {\bf E=e})$</span>:</p><p class="math-container">\[P(V \mid {\bf E=e}) = \frac{P(V, {\bf E=e})}{\sum_{V} P(V, {\bf E=e})}.\]</p><h2 id="Compiler-based-framework"><a class="docs-heading-anchor" href="#Compiler-based-framework">Compiler-based framework</a><a id="Compiler-based-framework-1"></a><a class="docs-heading-anchor-permalink" href="#Compiler-based-framework" title="Permalink"></a></h2><p>JunctionTrees.jl exploits Julia&#39;s metaprogramming capabilities to separate the algorithm into two phases: a compilation and a runtime phase. The compilation phase consists of the creation and subsequent optimization of the algorithm. The run-time phase consists of processing online data with the compiled algorithm to provide answers about variables of interest. This distinction between a compilation and a runtime phase opens a wide range of optimization possibilities in the offline stage. The figure below illustrates the compiler-based framework design used in JunctionTrees.jl.</p><p><img src="../compiler-based-framework.svg" alt/></p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>A clique in an undirected graph is a subgraph in which every pair of nodes is connected by an edge. A maximal clique is a clique that is not contained in a larger clique.</li><li class="footnote" id="footnote-huang1996inference"><a class="tag is-link" href="#citeref-huang1996inference">huang1996inference</a>Cecil Huang and Adnan Darwiche. Inference in belief networks: A procedural guide. <em>International Journal of Approximate Reasoning</em>, 15 (3):225–263, 1996. ISSN 0888-613X. doi: <a href="https://doi.org/10.1016/S0888-613X(96)00069-2">https://doi.org/10.1016/S0888-613X(96)00069-2</a>. URL <a href="https://www.sciencedirect.com/science/article/pii/S0888613X96000692">https://www.sciencedirect.com/science/article/pii/S0888613X96000692</a>.</li><li class="footnote" id="footnote-lauritzen1988local"><a class="tag is-link" href="#citeref-lauritzen1988local">lauritzen1988local</a>Steffen L Lauritzen and David J Spiegelhalter. Local computations with probabilities on graphical structures and their application to expert systems. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, 50(2):157–194, 1988.</li><li class="footnote" id="footnote-arnborg1987complexity"><a class="tag is-link" href="#citeref-arnborg1987complexity">arnborg1987complexity</a>Stefan Arnborg, Derek G Corneil, and Andrzej Proskurowski. Complexity of finding embeddings in ak-tree. <em>SIAM Journal on Algebraic Discrete Methods</em>, 8(2):277–284, 1987.</li><li class="footnote" id="footnote-jensen1994optimal"><a class="tag is-link" href="#citeref-jensen1994optimal">jensen1994optimal</a>Finn V. Jensen and Frank Jensen. Optimal junction trees. In <em>Proceedings of the Tenth International Conference on Uncertainty in Artificial Intelligence</em>, UAI’94, page 360–366, San Francisco, CA, USA, 1994. Morgan Kaufmann Publishers Inc. ISBN 1558603328.</li><li class="footnote" id="footnote-koller2009probabilistic"><a class="tag is-link" href="#citeref-koller2009probabilistic">koller2009probabilistic</a>Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques, pg 111. MIT press, 2009.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../usage/">Usage »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.15 on <span class="colophon-date" title="Wednesday 18 May 2022 11:13">Wednesday 18 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
